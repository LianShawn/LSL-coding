#the validation set approach
set.seed(1)
train <- sample(392,196)
#用linear regression
lm.fit <- lm(mpg ∼ horsepower, data = Auto, subset = train)
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
#用quadratic和cubic regression
lm.fit2 <- lm(mpg ∼ poly(horsepower, 2), data = Auto, subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ∼ poly(horsepower, 3), data = Auto, subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)

#Leave-one-out cross validation
#glm和lm是一样的，只有当glm中加了family=‘binomial’的时候，才是logistic regression
#glm和lm的不同是，glm可以搭配cv.glm一起使用，而cv.glm是boot的一部分

library(boot)
glm.fit <- glm(mpg ∼ horsepower, data = Auto) 
cv.err <- cv.glm(Auto , glm.fit)
cv.err$delta
#The cv.glm() function produces a list with several components. The two numbers in the delta vector contain the cross-validation results.
#重复cv.error的过程
cv.error <- rep(0, 10)
for (i in 1:10) {
  glm.fit <- glm(mpg ∼ poly(horsepower, i), data = Auto)
  cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]
  }
cv.error

#K-fold cross-validation
set.seed(17)
cv.seed.10 <- rep(0,10)
for (i in 1:10):
  glm.fit <- glm(mpg ~ poly(horsepower,i),data = Auto)
  cv.error.10[i] <- cv.glm(Auto,glm.fit,K=10)$delta[1]
  }
cv.error.10


#bootstrap
#create a function that computes the statistic of interest. then use boot()function
alpha.fn <- function(data, index) {
  X <- data$X[index]
  Y <- data$Y[index]
  (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y)) +}

set.seed (7)
alpha.fn(Portfolio, sample(100, 100, replace = T))

boot(Portfolio , alpha.fn, R = 1000)

#use bootstrap to estimate the accuracy of a linear regression model

#检验coefficient
boot.fn <- function(data, index)
  coef(lm(mpg ∼ horsepower, data = data, subset = index))
boot.fn(Auto , 1:392)

set.seed (1)
boot.fn(Auto, sample(392, 392, replace = T))

#use boot()function to compute the standard error of 1000 bootstrap estimates for the intercept and slope terms
boot(Auto, boot.fn, 1000)
#结果：
Bootstrap Statistics :
original    bias   std. error
t1* 39.936  0.0545   0.8413
t2* -0.158  -0.0006  0.0073

